{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Connectivity Analysis\n",
    "***\n",
    "\n",
    "Now we have an idea of three important components to analyzing neuroimaging data:\n",
    "\n",
    "1. Data manipulation\n",
    "2. Cleaning and confound regression\n",
    "3. Parcellation and signal extraction\n",
    "\n",
    "In this notebook the goal is to integrate these 3 basic components and perform a full analysis of group data using **Intranetwork Functional Connectivity (FC)**. \n",
    "\n",
    "Intranetwork functional connectivity is essentially a result of performing correlational analysis on mean signals extracted from two ROIs. Using this method we can examine how well certain resting state networks, such as the **Default Mode Network (DMN)**, are synchronized across spatially distinct regions. \n",
    "\n",
    "ROI-based correlational analysis forms the basis of many more sophisticated kinds of functional imaging analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Outline\n",
    "***\n",
    "\n",
    "The outline of the notebook is divided into two parts. The first part directly uses what you've learned and builds upon it to perform the final functional connectivity analysis on group data. \n",
    "\n",
    "The second part shows how we can use Nilearn's convenient wrapper functionality to perform the same task with *significantly less effort*. \n",
    "\n",
    "#### Part A: Manual computation \n",
    "1. Functional data cleaning and confound regression\n",
    "2. Applying a parcellation onto the data\n",
    "3. Computing the correlation between two ROI time-series\n",
    "\n",
    "\n",
    "#### Part B: Using Nilearn's high-level features\n",
    "1. Using NiftiLabelsMasker to extract cleaned time-series\n",
    "2. Computing the correlation between two ROI time-series\n",
    "3. Performing analysis on all subjects\n",
    "4. Visualization of final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nilearn import signal as sgl\n",
    "from nilearn import image as img\n",
    "from nilearn import plotting as plot\n",
    "from nilearn import datasets\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import bids\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick a single subject\n",
    "fmriprep_dir = '../data/ds000030/'\n",
    "sub = '10171'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use PyBIDS to parse BIDS data structure\n",
    "layout = bids.BIDSLayout(fmriprep_dir, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get resting state data (preprocessed, mask, and confounds file)\n",
    "func_files = layout.get(subject=sub, datatype='func', task='rest',  suffix='preproc')\n",
    "mask_files = layout.get(subject=sub, datatype='func', task='rest', suffix='brainmask')\n",
    "confound_files = layout.get(subject=sub, datatype='func', task='rest', suffix='confounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select MNI files\n",
    "func_file = func_files[0].path\n",
    "mask_file = mask_files=[0].path\n",
    "confound_file = confound_files[0].path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Manual Computation of Functional Connectivity\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Cleaning your functional data using filtering, dummy TR removal and confound regression\n",
    "The first step to any functional analysis is to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function to help extract our confound regressors from the .tsv file for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refer to part_06 for code + explanation\n",
    "def extract_confounds(confound_tsv,confounds,dt=True):\n",
    "    '''\n",
    "    Arguments:\n",
    "        confound_tsv                    Full path to confounds.tsv\n",
    "        confounds                       A list of confounder variables to extract\n",
    "        dt                              Compute temporal derivatives [default = True]\n",
    "        \n",
    "    Outputs:\n",
    "        confound_mat                    \n",
    "    '''\n",
    "    \n",
    "    #Load in data using Pandas then extract relevant columns\n",
    "    confound_df = pd.read_csv(confound_tsv,delimiter='\\t') \n",
    "    confound_df = confound_df[confounds]\n",
    "    \n",
    "    #If using temporal derivatives \n",
    "    if dt:\n",
    "        #For each column create a new column '<colname>_dt' containing the step-wise differences\n",
    "        for col in confound_df.columns:\n",
    "            confound_df['{}_dt'.format(col)] = confound_df[col].diff() \n",
    "    \n",
    "    #Convert into a matrix of values (timepoints)x(variable)\n",
    "    confound_mat = confound_df.values \n",
    "    \n",
    "    #Return confound matrix\n",
    "    return confound_mat\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Data given cannot be loaded because it is not compatible with nibabel format:\n<BIDSImageFile fil...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-dc8c295f69eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load functional image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtr_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfunc_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfunc_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_drop\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/scwg_neuroimaging/lib/python3.6/site-packages/nilearn/image/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(img, wildcards, dtype)\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mthat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maffine\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \"\"\"\n\u001b[0;32m--> 972\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwildcards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwildcards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/scwg_neuroimaging/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/scwg_neuroimaging/lib/python3.6/site-packages/nilearn/_utils/niimg.py\u001b[0m in \u001b[0;36mload_niimg\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         raise TypeError(\"Data given cannot be loaded because it is\"\n\u001b[1;32m    113\u001b[0m                         \u001b[0;34m\" not compatible with nibabel format:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                         + short_repr(niimg))\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_target_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Data given cannot be loaded because it is not compatible with nibabel format:\n<BIDSImageFile fil..."
     ]
    }
   ],
   "source": [
    "#Load functional image\n",
    "tr_drop = 4\n",
    "func_img = img.load_img(func_file)\n",
    "func_img = func_img.slicer[:,:,:,tr_drop+1:]\n",
    "\n",
    "#Extract confounds\n",
    "confounds = extract_confounds(confound_file,['X','Y','Z','RotX','RotY','RotZ','GlobalSignal',\n",
    "                                            'aCompCor01','aCompCor02'])\n",
    "confounds = confounds[tr_drop+1:,:] \n",
    "\n",
    "#Clean functional image\n",
    "clean_img = img.clean_img(func_img,confounds=confounds,low_pass=0.08,high_pass=0.009,t_r=2,\n",
    "                         mask_img=mask_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setting up the parcellation scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply a parcellation we'll have to specify a parcellation to use. \n",
    "For this analysis we'll be using a spatially separated version [Yeo 2011 - 7 Networks](https://www.ncbi.nlm.nih.gov/pubmed/21653723).\n",
    "\n",
    "We chose this parcellation since it nicely characterizes the **DMN**, our network of interest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Examine the original Yeo7 parcellation\n",
    "net7 = '../resources/rois/yeo_2011/Yeo_JNeurophysiol11_MNI152/Yeo2011_7Networks_MNI152_FreeSurferConformed1mm_LiberalMask.nii.gz'\n",
    "plot.plot_roi(net7,cmap='Paired',colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load in the spatially separated Yeo 2011 7 networks and view\n",
    "parcel_file = '../resources/rois/yeo_2011/Yeo_JNeurophysiol11_MNI152/relabeled_yeo_atlas.nii.gz' \n",
    "yeo_7 = img.load_img(parcel_file)\n",
    "plot.plot_roi(yeo_7,cmap='Paired',colorbar=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that in order to use the parcellation with our functional data it must have the same dimensions. It turns out that the parcellation schema has slightly different dimensions, so we need to resample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We use \"nearest\" to preserve the label values (a label of 2.42 for example, doesn't and shouldn't exist) \n",
    "resamp_yeo7 = img.resample_to_img(yeo_7,clean_img,interpolation='nearest') \n",
    "print(resamp_yeo7.shape)\n",
    "print(clean_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Intra-network functional connectivity analysis\n",
    "Intra-network functional connectivity analysis is determined by computing the correlation between the mean time-series of two spatially distinct regions within the same network. \n",
    "\n",
    "To perform this analysis requires a few simple steps:\n",
    "1. Select 2 ROIs from the same network (DMN) \n",
    "2. Extract the mean time-series from both regions \n",
    "3. Compute the correlation between the two mean ROI time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to select two ROIs from the DMN. We've already gone through the hassle of selecting these two regions but many possible combinations exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select two ROIs and visualize\n",
    "source_ROI = 44\n",
    "target_ROI = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualize the ROI, we can do this by masking our all values not matching our ROI\n",
    "source_mask = img.math_img('a == {}'.format(source_ROI), a=resamp_yeo7) \n",
    "\n",
    "#Apply the mask to the data\n",
    "masked_source = img.math_img('a*b',a=resamp_yeo7,b=source_mask) \n",
    "\n",
    "#Visualize\n",
    "plot.plot_roi(masked_source) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_mask = img.math_img('a == {}'.format(target_ROI),a=resamp_yeo7)\n",
    "masked_target = img.math_img('a*b',a=resamp_yeo7,b=target_mask)\n",
    "plot.plot_roi(masked_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our two regions selected, we'll now extract the mean time-series for each of our two ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recall that in the parcellation, each voxel is labelled with a number corresponding to a distinct parcel\n",
    "#We want to extract parcels belonging to our ROI.\n",
    "\n",
    "#Pull the voxels indices belonging to the ROI \n",
    "yeo7_data = resamp_yeo7.get_data() \n",
    "\n",
    "#Get voxel coordinates (x,y,z) list of source and target ROIs\n",
    "source_roi = np.where(yeo7_data == source_ROI)\n",
    "target_roi = np.where(yeo7_data == target_ROI)\n",
    "\n",
    "#Load up functional data to extract ROI voxels from\n",
    "func_data = clean_img.get_data()\n",
    "\n",
    "#Extract the list of voxel time-series belonging to each ROI\n",
    "#This is now a (roi voxel)x(timepoints) array\n",
    "source_ts = func_data[source_roi]\n",
    "target_ts = func_data[target_roi] \n",
    "\n",
    "#We want to compute the mean timeseries of each list of voxels (source and target) \n",
    "#This will be a (1) x (timepoints) vector\n",
    "mean_source_ts = np.mean(source_ts,axis=0)\n",
    "mean_target_ts = np.mean(target_ts,axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've extracted two average time-series, one from the source, and one from the target.\n",
    "The last step is to compute the correlation between them. This will tell us how well the average time-series from the two DMN regions synchronize with each other.\n",
    "\n",
    "To do this we use <code>np.corrcoef(x,y)</code> which returns a matrix of form:\n",
    "\n",
    "$$ \\rho=\n",
    "\\left( \\begin{matrix}\n",
    "\\rho_{1,1} & \\rho_{1,2} \\\\\n",
    "\\rho_{2,1} & \\rho_{2,2}\n",
    "\\end{matrix} \\right)\n",
    "$$\n",
    "\n",
    "The diagonals represent the correlation of signals with themselves. These are always $1$. The off-diagonal represents the correlation of one signal with another is exactly what we want. In addition the matrix is symmetric so: $\\rho_{1,2} = \\rho_{2,1}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute correlation and pull the value in the first row, second column\n",
    "correlation_matrix = np.corrcoef(mean_source_ts,mean_target_ts)\n",
    "source_targ_corr = correlation_matrix[0,1]\n",
    "print(source_targ_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Using nilearn's Labels Masker to extract the timeseries\n",
    "***\n",
    "nilearn has a built in function for extracting timeseries from functional files and doing a little extra signal processing at the same time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import a package from <code>nilearn</code>, called <code>input_data</code> which allows us to pull data using the parcellation file, and at the same time applying data cleaning!\n",
    "\n",
    "We first create an object using the parcellation file <code>yeo_7</code> and our cleaning settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nilearn import input_data\n",
    "\n",
    "masker = input_data.NiftiLabelsMasker(labels_img=yeo_7,\n",
    "                                      standardize=True,\n",
    "                                      memory='nilearn_cache',\n",
    "                                      verbose=1,\n",
    "                                      detrend=True,\n",
    "                                     low_pass = 0.08,\n",
    "                                     high_pass = 0.009,\n",
    "                                     t_r=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object <code>masker</code> is now able to be used on *any functional image of the same size*. What it means to *use the masker* is that you can automatically *apply a parcellation and extract data at the same time*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using nilearn's ConnectivityMeasure to calculate our correlation matrix\n",
    "\n",
    "The second step is to compute the functional connectivity (correlation) matrix. When we use <code>masker</code>, we can compute the correlation matrix *between all ROIs in our parcellation atlas at the same time*. Below we'll show an example on how to use the <code>masker</code> in order to compute correlations on our data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll automatically clean and average data for each of our ROIs at the same time. This is done using <code>masker.fit_transform</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_and_averaged_time_series = masker.fit_transform(func_img, confounds)\n",
    "cleaned_and_averaged_time_series.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then using this data we can calculate a *full correlation matrix* - this is the correlation between *all pairs of ROIs* in our parcellation scheme! We'll use another nilearn tool called <code>ConnectivityMeasure</code> from <code>nilearn.connectome</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the masker, we need to make an object that will calculate connectivity for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_measure = ConnectivityMeasure(kind='correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use <code>correlation_measure.fit_transform()</code> in order to calculate the full correlation matrix for our parcellated data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_correlation_matrix = correlation_measure.fit_transform(cleaned_and_averaged_time_series)\n",
    "full_correlation_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a matrix which has:\n",
    "\n",
    "- A number of rows matching the number of ROIs in our parcellation atlas\n",
    "- A number of columns, that also matches the number of ROIs in our parcellation atlas\n",
    "\n",
    "You can read this correlation matrix as follows:\n",
    "\n",
    "- Suppose we wanted to know the correlation between ROI 30 and ROI 40\n",
    "- Then Row 30, Column 40 gives us this correlation. \n",
    "- Row 40, Column 40 can also give us this correlation\n",
    "\n",
    "This is because the correlation of $A \\to B = B \\to A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Now try calculating correlation matrices for all subjects in our dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided some skeleton code to handle some of the logic. Try to fill in the blanks to the best of your ability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = layout.get_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pooled_subjects = []\n",
    "ctrl_subjects = []\n",
    "schz_subjects = []\n",
    "\n",
    "for sub in subjects:\n",
    "    func_file = layout.get(subject=sub, modality='func',\n",
    "                           type='preproc', return_type='file')[0]\n",
    "    \n",
    "    confound_file=layout.get(subject=sub, modality='func',\n",
    "                             type='confounds', return_type='file')[0]\n",
    "    \n",
    "    func_img = img.load_img(func_file)\n",
    "    func_img = func_img.slicer[:,:,:,tr_drop+1:]\n",
    "    \n",
    "    confounds = extract_confounds(confound_file,\n",
    "                                 ['X','Y','Z',\n",
    "                                 'RotX','RotY','RotZ',\n",
    "                                 'GlobalSignal','aCompCor01',\n",
    "                                 'aCompCor02'])\n",
    "    \n",
    "    confounds = confounds[tr_drop+1:,:]\n",
    "    \n",
    "    time_series = masker.fit_transform(func_img,confounds)\n",
    "    pooled_subjects.append(time_series)\n",
    "    \n",
    "    if sub.startswith('1'):\n",
    "        ctrl_subjects.append(time_series)\n",
    "    if sub.startswith('5'):\n",
    "        schz_subjects.append(time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helpful trick is that we can re-use the <code>correlation_measure</code> object we made earlier and apply it to a *list of subject data*! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctrl_correlation_matrices = correlation_measure.fit_transform(ctrl_subjects)\n",
    "schz_correlation_matrices = correlation_measure.fit_transform(schz_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have correlation matrices for each subject across two populations. The final step is to examine the differences between these groups in their correlation between ROI 43 and ROI 45:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Correlation Matrices and Group Differences\n",
    "\n",
    "An important step in any analysis is visualizing the data that we have. We've cleaned data, averaged data and calculated correlations but we don't actually know what it looks like! Visualizing data is important to ensure that we don't throw pure nonsense into our final statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize data we'll be using a python package called <code>seaborn</code> which will allow us to create statistical visualizations pretty easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrices(matrices, matrix_kind):\n",
    "    n_matrices = len(matrices)\n",
    "    fig = plt.figure(figsize=(n_matrices * 4, 4))\n",
    "    for n_subject, matrix in enumerate(matrices):\n",
    "        plt.subplot(1, n_matrices, n_subject + 1)\n",
    "        matrix = matrix.copy()  # avoid side effects\n",
    "        # Set diagonal to zero, for better visualization\n",
    "        np.fill_diagonal(matrix, 0)\n",
    "        vmax = np.max(np.abs(matrix))\n",
    "        title = '{0}, subject {1}'.format(matrix_kind, n_subject)\n",
    "        plot.plot_matrix(matrix, vmin=-vmax, vmax=vmax, cmap='RdBu_r',\n",
    "                             title=title, figure=fig, colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_matrices(ctrl_correlation_matrices, 'correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_matrices(schz_correlation_matrices, 'correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctrl_correlation_matrices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the full set of connectivity values across multiple ROIs, we'd like to pull matrices specific to the ROI's of interest (44,46). \n",
    "We'll first pull the set of intra-network connectivities for our two ROIs of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctrl_roi_vec = ctrl_correlation_matrices[:,43,45]\n",
    "schz_roi_vec = schz_correlation_matrices[:,43,45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll visualize the final results using Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn visualization is best achieved using a Pandas dataframe (much like R's dataframes). A dataframe is essentially a spreadsheet-like table and is easily created using numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create control dataframe\n",
    "ctrl_df = pd.DataFrame(data={'dmn_corr':ctrl_roi_vec, 'group':'control'})\n",
    "scz_df = pd.DataFrame(data={'dmn_corr':schz_roi_vec, 'group' : 'schizophrenia'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stack the two dataframes together\n",
    "df = pd.concat([ctrl_df,scz_df],ignore_index=True)\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualize results\n",
    "plot = plt.figure(figsize=(5,5))\n",
    "ax = sns.boxplot(x='group',y='dmn_corr',data=df,palette='Set3')\n",
    "ax = sns.swarmplot(x='group',y='dmn_corr',data=df,color='0.25')\n",
    "ax.set_title('DMN Intra-network Connectivity')\n",
    "ax.set_ylabel(r'Intra-network connectivity $\\mu_\\rho$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing correlations was simple, but interpreting results... \n",
    "# \"Science is hard\" - Colin Hawco"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
