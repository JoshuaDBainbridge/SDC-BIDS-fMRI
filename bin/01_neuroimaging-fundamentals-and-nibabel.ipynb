{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.exercise {    \n",
       "    background-color: #f8ed62;\n",
       "    border-color: #dab600;\n",
       "    border-left: 5px solid #dab600;\n",
       "    padding: 0.5em;\n",
       "    }\n",
       " </style>\n",
       "\n",
       "<style>\n",
       "div.solution {    \n",
       "    background-color: #ee7942;\n",
       "    border-color: #a0522d;\n",
       "    border-left: 5px solid #a0522d;\n",
       "    padding: 0.5em;\n",
       "    }\n",
       " </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "import random\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../static/css/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Python?\n",
    "\n",
    "- free, open source\n",
    "- one platform for data pre-processing, visualization and analysis\n",
    "- reproducible code\n",
    "- large number of user-developed packages (eg. nibabel, nilearn)\n",
    "- easy interaction with state-of-the art neuroimaging software (eg. FSL, ANTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of MR Scans\n",
    "\n",
    "<img src=\"../static/images/mr_scan_types.png\" alt=\"Drawing\" align=\"middle\" width=\"500px\"/>\n",
    "\n",
    "For this tutorial, we'll be focusing on T1w and resting state fMRI scans.\n",
    "\n",
    "### Neuroimaging File Formats\n",
    "\n",
    "|Format Name | File Extension | Origin |\n",
    "|---|---|---|\n",
    "| Analyze | .img/.hdr | Analyze Software, Mayo Clinic |\n",
    "| DICOM | none | ACR/NEMA Consortium |\n",
    "| NIfTI | .nii or .img/.hdr | Neuroimaging Informatics Technology Initiative |\n",
    "| MINC | .mnc | Montreal Neurological Institute |\n",
    "| NRRD | .nrrd | |\n",
    "\n",
    "<img src=\"../static/images/dicom_to_nifti.png\" alt=\"Drawing\" align=\"middle\" width=\"300px\"/>\n",
    "\n",
    "From the MRI scanner, images are initially collected in the DICOM format and can be converted to NIfTI using [dcm2niix](https://github.com/rordenlab/dcm2niix).\n",
    "\n",
    "### Intro to NIfTI\n",
    "\n",
    "NIfTI is one of the most ubiquitous file formats for storing neuroimaging data. We'll cover a few details to get started working with them. If you're interested in learning more about NIfTI images, we highly recommend [this blog post about the NIfTI format](http://brainder.org/2012/09/23/the-nifti-file-format/).\n",
    "\n",
    "### Reading NIfTI Images\n",
    "\n",
    "[NiBabel](http://nipy.org/nibabel/) is a Python package for reading and writing neuroimaging data. To learn more about how NiBabel handles NIfTIs, check out the [Working with NIfTI images](http://nipy.org/nibabel/nifti_images.html) page of the NiBabel documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, use the `load()` function to create a NiBabel image object from a NIfTI file. We'll load in a T1w image from the dataset we'll be using for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_img = nib.load('../data/ds000030/sub-10788/anat/sub-10788_T1w.nii.gz')\n",
    "type(t1_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main components of a NIfTI image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. [Header](http://nipy.org/nibabel/nibabel_images.html#the-image-header): contains metadata about the image, such as image dimensions, data type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr = t1_img.header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily access specific metadata from the NiBabel image header object through dictionary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=exercise>\n",
    "    <b>EXERCISE:</b> Extract the value of <code>pixdim</code> from <code>nii_hdr</code>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=solution>\n",
    "    <b>SOLUTION:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr['pixdim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data\n",
    "The data is a multidimensional array representing the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data = t1_img.get_data()\n",
    "t1_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(t1_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check some basic properties of the array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=exercise>\n",
    "    <b>EXERCISE:</b> How many dimesnions does <code>t1_data</code> have? What are is the size of each dimension? What is the data type?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=solution>\n",
    "    <b>SOLUTION:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the data always has at least 3 dimensions (X, Y, and Z) and sometimes a 4th, T (time).  \n",
    "This T1w image has 3 dimensions. The brain was scanned in 176 slices with a resolution of 256 x 256 voxels per slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type of an image controls the range of possible intensities. As the number of possible values increases, the amount of space the image takes up in memory also increases.\n",
    "\n",
    "| Data Type | Range | Number of Values |\n",
    "|---|---|---|\n",
    "| uint8 | 0, 255 | 256 |\n",
    "| uint16 | -128, 127 | 256 |\n",
    "| uint 16 | 0, 2^16 | 2^16 |\n",
    "| int16 | -2^15, 2^15 | 2^16 |\n",
    "| float16 | ~-2^16, ~2^16 | >>2^16 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. [Affine](http://nipy.org/nibabel/coordinate_systems.html): tells the position of the image array data in a *reference space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The affine array tells the position of the image array data in a *reference space*. It translates between data-space and world-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_affine = t1_img.affine\n",
    "nii_affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=exercise>\n",
    "    <b>EXERCISE:</b> Explore some of the other methods that can be called on the NIfTI image.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With Image Data\n",
    "\n",
    "#### Slicing\n",
    "\n",
    "n-dimensional images are just stacks of numpy arrays.  Each value in the array is assigned to an x, y or z coordinate.  \n",
    "<img src=\"../static/images/numpy_arrays.png\" alt=\"Drawing\" align=\"middle\" width=\"500px\"/>\n",
    "\n",
    "You'll recall our example T1w image is a 3D image with dimensions $176 \\times 256 \\times 256$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=exercise>\n",
    "    <b>EXERCISE:</b> Select the central slice by indexing <code>t1_data</code> eg.(<code>t1_data[x, y, z]</code>)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=solution>\n",
    "    <b>SOLUTION:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of indexing the data array, we can also call the `slicer()` method on the NiBabel image object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing\n",
    "Let's visualize the central slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(central_slice, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the image is rotated. :( Don't worry, we can fix this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rot_central_slice = np.rot90(central_slice, k=1)\n",
    "plt.imshow(rot_central_slice, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that so far, we've only seen a sagittal slice. Lets visualize the sagittal, axial and coronal slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display a row of slices\n",
    "def show_slices(slices):\n",
    "    \"\"\" Function to display row of image slices \"\"\"\n",
    "    fig, axes = plt.subplots(1, len(slices))\n",
    "    for i, slice in enumerate(slices):\n",
    "        axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")\n",
    "        for ax in axes:\n",
    "            ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_0 = t1_data[87, :, :]\n",
    "slice_1 = t1_data[:, 127, :]\n",
    "slice_2 = t1_data[:, :, 127]\n",
    "show_slices([slice_0, slice_1, slice_2])\n",
    "plt.suptitle(\"Center slice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this is fine but NiBabel makes it even easier to visualize all three planes. Call the `orthoview()` method on the NiBabel image object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_img.orthoview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy has a `reshape()` function for reshaping the data array. Let's say we want to convert this 3D array into a a 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data_2d = t1_data.reshape(np.prod(t1_data.shape[:-1]), t1_data.shape[-1])\n",
    "t1_data_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masks\n",
    "Next, we will see how to segment the brain from the black background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(t1_data.flatten(), bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_mask = t1_data > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(t1_mask[87, :, :], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.where(t1_mask, t1_data, 0)\n",
    "plt.imshow(test[87, :, :], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing NIfTI Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the mask we just created to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask = nib.Nifti1Image(test, nii_affine, nii_hdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask.to_filename('../data/test_mask.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
