{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Connectivity Analysis\n",
    "***\n",
    "\n",
    "Now we have an idea of three important components to analyzing neuroimaging data:\n",
    "\n",
    "1. Data manipulation\n",
    "2. Cleaning and confound regression\n",
    "3. Parcellation and signal extraction\n",
    "\n",
    "In this notebook the goal is to integrate these 3 basic components and perform a full analysis of group data using **Seed-based Functional Connectivity (FC)**. \n",
    "\n",
    "Seed-based functional connectivity is essentially a result of performing correlational analysis on signals extracted from an ROI with voxels. Using this technique we can establish highly correlative regions in resting state data which form **functional networks**. \n",
    "\n",
    "This analysis forms a basis for many other sophisticated techniques in neuroimaging research. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Outline\n",
    "***\n",
    "\n",
    "The outline of the notebook is divided into two parts. The first part directly uses what you've learned and builds upon it to perform the final functional connectivity analysis on group data. \n",
    "\n",
    "The second part shows how we can use Nilearn's convenient wrapper functionality to perform the same task with *significantly less effort*. \n",
    "\n",
    "#### Part A: Manual computation \n",
    "1. Functional data cleaning and confound regression\n",
    "2. Applying a parcellation onto the data\n",
    "3. Seed-based functional connectivity analysis\n",
    "4. Visualization\n",
    "\n",
    "#### Part B: Using Nilearn's high-level features\n",
    "1. Using NiftiMapsMasker to extract cleaned time-series\n",
    "2. Performing seed-based functional connectivity analysis\n",
    "3. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nilearn import signal as sgl\n",
    "from nilearn import image as img\n",
    "from nilearn import plotting as plot\n",
    "from nilearn import datasets\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = '70060'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting up directories\n",
    "func_dir = '../data/func/'\n",
    "\n",
    "#Pre-processed functional data in MNI space\n",
    "func_file = 'sub-{}_task-rest_bold_space-MNI152NLin2009cAsym_preproc.nii.gz'.format(sub)\n",
    "func_path = os.path.join(func_dir,func_file) \n",
    "\n",
    "#Confounds.tsv extracted using FMRIPREP \n",
    "confound_file = 'sub-{}_task-rest_bold_confounds.tsv'.format(sub)\n",
    "confound_path = os.path.join(func_dir,confound_file) \n",
    "\n",
    "#MNI Brainmask outputted from FMRIPREP\n",
    "mask_file = 'sub-{}_task-rest_bold_space-MNI152NLin2009cAsym_brainmask.nii.gz'.format(sub)\n",
    "mask_path = os.path.join(func_dir,mask_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Manual Computation of Seed-based functional connectivity\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Cleaning your functional data using filtering, dummy TR removal and confound regression\n",
    "The first step to any functional analysis is to clean the data. We're going to make a python function that will handle confound cleaning for us:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to define a function to handle converting our confounds.tsv into a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Refer to part_06 for code + explanation\n",
    "def extract_confounds(confound_tsv,confounds,dt=True):\n",
    "    '''\n",
    "    Arguments:\n",
    "        confound_tsv                    Full path to confounds.tsv\n",
    "        confounds                       A list of confounder variables to extract\n",
    "        dt                              Compute temporal derivatives [default = True]\n",
    "        \n",
    "    Outputs:\n",
    "        confound_mat                    \n",
    "    '''\n",
    "    \n",
    "    #Load in data using Pandas then extract relevant columns\n",
    "    confound_df = pd.read_csv(confound_tsv,delimiter='\\t') \n",
    "    confound_df = confound_df[confounds]\n",
    "    \n",
    "    #If using temporal derivatives \n",
    "    if dt:\n",
    "        #For each column create a new column '<colname>_dt' containing the step-wise differences\n",
    "        for col in confound_df.columns:\n",
    "            confound_df['{}_dt'.format(col)] = confound_df[col].diff() \n",
    "    \n",
    "    #Convert into a matrix of values (timepoints)x(variable)\n",
    "    confound_mat = confound_df.values \n",
    "    \n",
    "    #Return confound matrix\n",
    "    return confound_mat\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load functional image\n",
    "func_img = img.load_img(func_path)\n",
    "func_img = func_img.slicer[:,:,:,5:]\n",
    "\n",
    "#Extract confounds\n",
    "confounds = extract_confounds(confound_path,['X','Y','Z','RotX','RotY','RotZ','GlobalSignal'])\n",
    "confounds = confounds[5:,:] \n",
    "\n",
    "#Clean functional image\n",
    "clean_img = img.clean_img(func_img,confounds=confounds,low_pass=0.08,high_pass=0.009,t_r=2,\n",
    "                         mask_img=mask_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setting up the parcellation scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply a parcellation we'll have to specify a parcellation to use. \n",
    "For this analysis we'll be using [Craddock 2012 - 200 ROIs](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3838923/) as our parcellation scheme since it contains relatively simple ROIs that won't be too difficult to work with...\n",
    "\n",
    "First we'll pull in our parcellation then extract the version containing 200 ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_dir = '../resources/rois/' \n",
    "fetch_atlas = datasets.fetch_atlas_craddock_2012(parcel_dir) \n",
    "\n",
    "#Notice cc_atlas is 4D, where the 4th dimension contains different types of parcellations\n",
    "cc_atlas = img.load_img(fetch_atlas['random']) \n",
    "\n",
    "#Index 19, contains the 200 ROI parcellation we want to use\n",
    "cc200 = cc_atlas.slicer[:,:,:,19]\n",
    "\n",
    "#Let's visualize it\n",
    "plot.plot_roi(cc200,cmap='Paired')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that in order to use the parcellation with our functional data it must have the same dimensions. It turns out that the parcellation schema has slightly different dimensions, so we need to resample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use \"nearest\" to preserve the label values (a label of 2.42 for example, doesn't and shouldn't exist) \n",
    "resamp_cc200 = img.resample_to_img(cc200,clean_img,interpolation='nearest') \n",
    "print(resamp_cc200.shape)\n",
    "print(clean_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Seed-based functional connectivity analysis\n",
    "A seed-based functional connectivity is determined using the **mean time-series** from a single parcel (the seed) then correlating that with every other voxel in the brain. The idea behind this is to get an idea of how functionally connected other voxels are to a parcel. This analysis produces a **statistical map** which is then used in further analyses. \n",
    "\n",
    "In this section we will compute the mean time-series of a parcel from Craddock 200, compute the seed-based functional connectivity, then visualize on a glass-brain plot.\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to select an ROI as the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select ROI and visualize\n",
    "ROI = 174\n",
    "\n",
    "#Visualize the ROI, we can do this by masking our all values not matching our ROI\n",
    "roi_mask = img.math_img('a == {}'.format(ROI), a=resamp_cc200) \n",
    "\n",
    "#Apply the mask to the data\n",
    "masked_resamp_cc200 = img.math_img('a*b',a=resamp_cc200,b=roi_mask) \n",
    "\n",
    "#Visualize\n",
    "plot.plot_roi(masked_resamp_cc200) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we extract the time-series of the voxels from the seed and compute the mean time-series across voxels in the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recall that in the parcellation, each voxel is labelled with a number corresponding to a distinct parcel\n",
    "#We want to extract parcels belonging to our ROI.\n",
    "\n",
    "#Pull the voxels indices belonging to the ROI \n",
    "rcc200_data = resamp_cc200.get_data() \n",
    "\n",
    "#This yields a set of x,y,z coordinates corresponding to voxels belonging in the ROI \n",
    "roi = np.where(rcc200_data==ROI) \n",
    "\n",
    "#Now we'll take these coordinates and use them to pull the ROI time-series from our clean functional image\n",
    "func_data = clean_img.get_data()\n",
    "\n",
    "#This is now a matrix of size (voxels)x(timepoints) \n",
    "func_roi = func_data[roi]\n",
    "\n",
    "#We want to take the average across voxels, we do this using numpy\n",
    "mean_ts = np.mean(func_roi,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step in seed-based connectivity is to compute correlations between the mean time-series and every other voxels in the brain. \n",
    "\n",
    "**BUT** \n",
    "\n",
    "If we compute correlations of our seed-regions to *all other voxels* in our functional image, we will be including background voxels (non-brain regions) in our correlational analysis as well. This won't necessarily pose a problem in our analysis if we make sure to apply a brain mask after our analysis. \n",
    "\n",
    "**BUT (again)**\n",
    "\n",
    "Including non-brain regions in our correlation analysis will *slow us down significantly*. To speed up the analysis we will set non-brain correlations to 0, via *masking the voxels we correlate with*. This way we only perform the time-series correlation if and only if a particular voxel is a brain voxel\n",
    "\n",
    "***\n",
    "\n",
    "First we will load in the MNI space Mask image, then get the voxel coordinates where the mask is non-zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 1: Load in mask data then get coordinates of non-zero voxels\n",
    "#Since this mask is generated from the MNI space functional data, the dimensions should match\n",
    "mask_img = img.load_img(mask_path) \n",
    "mask_data = mask_img.get_data() \n",
    "\n",
    "#Get mask region x,y,z coordinates\n",
    "mask_x,mask_y,mask_z = np.where(mask_data == 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final output of our seed-based functional connectivity analysis will be a 3D volume, where each \"voxel\" will be assigned an $r$ correlation value with the seed mean timeseries (<code>mean_ts</code>). \n",
    "We'll initialize a 3D volume, where the values start off as zero, then assign $r$ values for each voxel, this will be our statistical map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create an empty image for storing our statistical volume, needs to match x,y,z dimensions of our functional image\n",
    "#Which is identical to the mask\n",
    "stat_data = np.zeros_like(mask_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we loop through each of voxel coordinates contained within our mask, pull the time-series from the functional data and correlate with mean time series (<code>mean_ts</code>) we computed from our ROI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Zip pairs up the x,y,z of each voxel, so that each loop's x,y,z will be associated with a particular voxel\n",
    "for x,y,z in zip(mask_x,mask_y,mask_z): \n",
    "    \n",
    "    #Grab the functional time-series for this particular voxel \n",
    "    rst_series = func_data[x,y,z,:]\n",
    "    \n",
    "    #Compute Pearson product-moment correlation ROI mean time-series and a single brain voxel\n",
    "    r = np.corrcoef([mean_ts,rst_series])[0,1]\n",
    "    \n",
    "    #Assign r to voxel x,y,z in our statistical volume\n",
    "    stat_data[x,y,z] = r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4: Visulization of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize our results, nilearn requires that our data be in nibabel Nifti1Image format. Recall that to create a Nifti1Image we need both our data (<code>stat_data</code>), and an affine matrix. We'll steal this affine matrix from our functional data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pull affine matrix from functional image\n",
    "affine = func_img.affine\n",
    "\n",
    "#Create statistical Nifti1Image\n",
    "stat_img = nib.Nifti1Image(stat_data,affine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_img(stat_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D Interactive viewer\n",
    "plot.view_img(stat_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
