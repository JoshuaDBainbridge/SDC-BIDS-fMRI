{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain Atlases\n",
    "\n",
    "A brain atlas is a labeling of a volume. Each voxel contains a label, instead of a gray value. These labels are numeric. Each number corresponds to a region of interest (ROI).\n",
    "\n",
    "Why ROIs?\n",
    "1. Explore the data (see signal in areas of interest plotted for each condition or plotted against other variables of interest)\n",
    "2. Limit number of statistical tests, controlling for Type I error\n",
    "3. Limit statistical tests to a region that is functionally defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these atlases are also explained here: https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Atlases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Atlases\n",
    "\n",
    "A full list of nilearn atlases can be found here: http://nilearn.github.io/modules/reference.html#module-nilearn.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Atlas\n",
    "\n",
    "Since we're using resting state fMRI data, it makes sense to use an atlas defined using resting state fMRI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_dir = '../resources/rois/' \n",
    "fetch_atlas = datasets.fetch_atlas_craddock_2012(parcel_dir) \n",
    "\n",
    "#Notice cc_atlas is 4D, where the 4th dimension contains different types of parcellations\n",
    "cc_atlas = img.load_img(fetch_atlas['random']) \n",
    "\n",
    "#Index 19, contains the 200 ROI parcellation we want to use\n",
    "cc200 = cc_atlas.slicer[:,:,:,19]\n",
    "\n",
    "#Let's visualize it\n",
    "plot.plot_roi(cc200,cmap='Paired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "from nilearn import image as img\n",
    "\n",
    "parcel_dir = '../resources/rois/'\n",
    "get_parcellations = datasets.fetch_atlas_craddock_2012(parcel_dir)\n",
    "cc_atlas = img.load_img(get_parcellations['random']) \n",
    "craddock_atlas = cc_atlas.slicer[:,:,:,19]\n",
    "\n",
    "#print('Atlas ROIs are located in nifti image (4D) at: %s' %\n",
    "#       atlas_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at that atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "\n",
    "plotting.plot_roi(atlas_filename)\n",
    "print('Number of parcellations:' + str(np.unique(craddock_atlas.get_data()).shape[0] -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, let's load an example 4D fmri time-series for one subject\n",
    "\n",
    "We have prepared some data especially for this tutorial. It is based on an open dataset of children and young adults. More details can be found here\n",
    "\n",
    "And let's have a look at that 4D resting-state image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_filenames = data.func[0]\n",
    "print('fmri timeseries are located in nifti image (4D) at: %s' %\n",
    "       fmri_filenames)  # 4D data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's have a look at that 4D resting-state image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(fmri_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "\n",
    "masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=True, \n",
    "                           memory='nilearn_cache', verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting fancier with nilearn\n",
    "\n",
    "nilearn was built by people doing machine learning of resting state fMRI data using sci-kit learn.\n",
    "\n",
    "It has A LOT of functionallity beyond what we have time to teach here. Including:\n",
    "+ image manipulation (smoothing, resampling)\n",
    "+ algorithms (ICA and dictionary learning) for parcellating your own dataset (i.e. defining your own ROIS) \n",
    "+ timeseries extraction with many many options for filtering, detrending \n",
    "+ multiple methods for covariance esimtaiton (i.e. partial correlation, covariance, lasso..)\n",
    "+ machine learning and cross validation\n",
    "\n",
    "They also did a beautiful job of building a large set of ipython notebook tutorials to teach you about all these methods.\n",
    "\n",
    "Go to the [the nilean website](http://nilearn.github.io/index.html) for more info.\n",
    "\n",
    "Let's use another example to see some of the more complex things nilearn can do...\n",
    "\n",
    "We'll start by using the data fetcher to grab a different atlas. This one (dosenbach_2010) if a set of coordinates in the brain to sample from.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "dosenbach = datasets.fetch_coords_dosenbach_2010()\n",
    "print(dosenbach.description.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using nilearn's sphere masker to extract the timeseries\n",
    "\n",
    "nilearn has a built in function for extracting timeseries from functional files and doing a little extra signal processing at the same time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create small ROIs (usually spheres) at the peaks of activation clusters. In the case of large clusters, it can be useful to create ROIs for additional local maxima in order to explore multiple regions within the cluster. To ensure that the sphere only contains voxels that were truly activated, these spheres are often masked with the thresholded activation map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import input_data\n",
    "\n",
    "spheres_masker = input_data.NiftiSpheresMasker(\n",
    "    seeds=dosenbach.rois, #the seeds are the dosenbach roi atlas\n",
    "    smoothing_fwhm=4, radius=4.5, # set the radius of a sphere around the roi you want extracted\n",
    "    standardize=True, # the time-series are centered and normed (mean 0, variance 1 in the time dimension)\n",
    "    detrend=True, low_pass=0.1, high_pass=0.01, t_r=2.5, confound = adhd.confounds[0]) # additional signal cleaning and filtering params\n",
    "\n",
    "timeseries = spheres_masker.fit_transform(func)\n",
    "\n",
    "print(\"the shape of the timeseries is {}\".format(timeseries.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using nilearn's ConnectivityMeasure to calculate our correlation matrix\n",
    "\n",
    "Avalable options are “correlation”, “partial correlation”, “tangent”, “covariance”, “precision” or other utilites in sci-py could be plugged in ([see here for an example](http://nilearn.github.io/auto_examples/03_connectivity/plot_multi_subject_connectome.html#sphx-glr-auto-examples-03-connectivity-plot-multi-subject-connectome-py))\n",
    "\n",
    "Let's do partial correlation this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn import plotting\n",
    "\n",
    "correlation_measure = ConnectivityMeasure(kind='covariance')\n",
    "dosenbach_matrix = correlation_measure.fit_transform([timeseries])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.clustermap(dosenbach_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "coords = np.vstack((\n",
    "    dosenbach.rois['x'],\n",
    "    dosenbach.rois['y'],\n",
    "    dosenbach.rois['z'],\n",
    ")).T\n",
    "\n",
    "plotting.plot_connectome(dosenbach_matrix, node_coords = coords, edge_threshold='98%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now let's repeat the sphere's with confound cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import input_data\n",
    "\n",
    "spheres_masker = input_data.NiftiSpheresMasker(\n",
    "    seeds=dosenbach.rois, #the seeds are the dosenbach roi atlas\n",
    "    smoothing_fwhm=4, radius=4.5, # set the radius of a sphere around the roi you want extracted\n",
    "    standardize=True, # the time-series are centered and normed (mean 0, variance 1 in the time dimension)\n",
    "    detrend=True, low_pass=0.1, high_pass=0.01, t_r=2.5) # additional signal cleaning and filtering params\n",
    "\n",
    "timeseries = spheres_masker.fit_transform(func, confounds=func_confounds)\n",
    "\n",
    "print(\"the shape of the timeseries is {}\".format(timeseries.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_measure = ConnectivityMeasure(kind='covariance')\n",
    "dosenbach_matrix = correlation_measure.fit_transform([timeseries])[0]\n",
    "seaborn.clustermap(dosenbach_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now let's try cleaning the whole image with image.clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image clearning inside nilearn\n",
    "\n",
    "cleaned_func = img.clean_img(func, confounds=func_confounds, low_pass=0.1, high_pass=0.01, t_r=2.0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti label masker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
