{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.exercise {    \n",
       "    background-color: #f8ed62;\n",
       "    border-color: #dab600;\n",
       "    border-left: 5px solid #dab600;\n",
       "    padding: 0.5em;\n",
       "    }\n",
       " </style>\n",
       "\n",
       "<style>\n",
       "div.solution {    \n",
       "    background-color: #ee7942;\n",
       "    border-color: #a0522d;\n",
       "    border-left: 5px solid #a0522d;\n",
       "    padding: 0.5em;\n",
       "    }\n",
       " </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "import random\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../static/css/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Python?\n",
    "\n",
    "- free, open source\n",
    "- one platform for data pre-processing, visualization and analysis\n",
    "- reproducible code\n",
    "- large number of user-developed packages (eg. nibabel, nilearn)\n",
    "- easy interaction with state-of-the art neuroimaging software (eg. FSL, ANTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of MR Scans\n",
    "\n",
    "<img src=\"../static/images/mr_scan_types.png\" alt=\"Drawing\" align=\"middle\" width=\"500px\">\n",
    "\n",
    "For this tutorial, we'll be focusing on T1w and resting state fMRI scans.\n",
    "\n",
    "### Neuroimaging File Formats\n",
    "\n",
    "|Format Name | File Extension | Origin |\n",
    "|---|---|---|\n",
    "| Analyze | .img/.hdr | Analyze Software, Mayo Clinic |\n",
    "| DICOM | none | ACR/NEMA Consortium |\n",
    "| NIfTI | .nii or .img/.hdr | Neuroimaging Informatics Technology Initiative |\n",
    "| MINC | .mnc | Montreal Neurological Institute |\n",
    "| NRRD | .nrrd | |\n",
    "\n",
    "<img src=\"../static/images/dicom_to_nifti.png\" alt=\"Drawing\" align=\"middle\" width=\"300px\"/>\n",
    "\n",
    "From the MRI scanner, images are initially collected in the DICOM format and can be converted to NIfTI using [dcm2niix](https://github.com/rordenlab/dcm2niix).\n",
    "\n",
    "### Intro to NIfTI\n",
    "\n",
    "NIfTI is one of the most ubiquitous file formats for storing neuroimaging data. We'll cover a few details to get started working with them. If you're interested in learning more about NIfTI images, we highly recommend [this blog post about the NIfTI format](http://brainder.org/2012/09/23/the-nifti-file-format/).\n",
    "\n",
    "### Reading NIfTI Images\n",
    "\n",
    "[NiBabel](http://nipy.org/nibabel/) is a Python package for reading and writing neuroimaging data. To learn more about how NiBabel handles NIfTIs, check out the [Working with NIfTI images](http://nipy.org/nibabel/nifti_images.html) page of the NiBabel documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, use the `load()` function to create a NiBabel image object from a NIfTI file. We'll load in a T1w image from the dataset we'll be using for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nibabel.nifti1.Nifti1Image"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_img = nib.load('../data/ds000030/sub-10171/anat/sub-10171_T1w.nii.gz')\n",
    "type(t1_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NiBabel image object contains several components called \"attributes\" in Python's terminology. To see all of these attributes, type `t1_img.` and <kbd>Tab</kbd>.  \n",
    "There are three main attributes that we'll discuss today:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. [Header](http://nipy.org/nibabel/nibabel_images.html#the-image-header): contains metadata about the image, such as image dimensions, data type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b''\n",
      "dim_info        : 0\n",
      "dim             : [  3 176 256 256   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1.   1.   1.   1.   2.53 1.   1.   1.  ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b'FreeSurfer May 13 2013'\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : -86.24172\n",
      "qoffset_y       : -114.76041\n",
      "qoffset_z       : -140.12009\n",
      "srow_x          : [  1.        0.        0.      -86.24172]\n",
      "srow_y          : [   0.         1.         0.      -114.76041]\n",
      "srow_z          : [   0.         0.         1.      -140.12009]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    }
   ],
   "source": [
    "t1_hdr = t1_img.header\n",
    "print(t1_hdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NiBabel image header is a Python **dictionary**. Dictionaries are containers that hold pairs of objects - keys and values. Let's take a look at all of the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sizeof_hdr',\n",
       " 'data_type',\n",
       " 'db_name',\n",
       " 'extents',\n",
       " 'session_error',\n",
       " 'regular',\n",
       " 'dim_info',\n",
       " 'dim',\n",
       " 'intent_p1',\n",
       " 'intent_p2',\n",
       " 'intent_p3',\n",
       " 'intent_code',\n",
       " 'datatype',\n",
       " 'bitpix',\n",
       " 'slice_start',\n",
       " 'pixdim',\n",
       " 'vox_offset',\n",
       " 'scl_slope',\n",
       " 'scl_inter',\n",
       " 'slice_end',\n",
       " 'slice_code',\n",
       " 'xyzt_units',\n",
       " 'cal_max',\n",
       " 'cal_min',\n",
       " 'slice_duration',\n",
       " 'toffset',\n",
       " 'glmax',\n",
       " 'glmin',\n",
       " 'descrip',\n",
       " 'aux_file',\n",
       " 'qform_code',\n",
       " 'sform_code',\n",
       " 'quatern_b',\n",
       " 'quatern_c',\n",
       " 'quatern_d',\n",
       " 'qoffset_x',\n",
       " 'qoffset_y',\n",
       " 'qoffset_z',\n",
       " 'srow_x',\n",
       " 'srow_y',\n",
       " 'srow_z',\n",
       " 'intent_name',\n",
       " 'magic']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_hdr.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the value stored by a given key by typing:\n",
    "\n",
    "```python\n",
    "t1_hdr['<key_name>']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=exercise>\n",
    "    <b>EXERCISE:</b> Extract the value of <code>pixdim</code> from <code>t1_hdr</code>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=solution>\n",
    "    <b>SOLUTION:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr['pixdim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data\n",
    "The data is a multidimensional array representing the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[27., 10.,  6., ...,  1.,  1.,  0.],\n",
       "        [ 6., 57.,  6., ...,  0.,  2.,  0.],\n",
       "        [27., 20., 26., ...,  2.,  2.,  0.],\n",
       "        ...,\n",
       "        [ 2.,  2.,  8., ...,  4.,  2.,  0.],\n",
       "        [ 1.,  5.,  9., ...,  3.,  1.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[41., 47., 29., ...,  0.,  5.,  0.],\n",
       "        [47., 23., 55., ...,  3.,  3.,  0.],\n",
       "        [40., 23., 13., ...,  3.,  3.,  0.],\n",
       "        ...,\n",
       "        [ 3.,  3.,  7., ...,  1.,  5.,  0.],\n",
       "        [ 2.,  2.,  7., ...,  3.,  5.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[10., 29., 38., ...,  3.,  3.,  0.],\n",
       "        [46., 16.,  9., ...,  0.,  3.,  0.],\n",
       "        [16., 22., 48., ...,  2.,  3.,  0.],\n",
       "        ...,\n",
       "        [ 1.,  2.,  6., ...,  3.,  3.,  0.],\n",
       "        [ 4.,  7.,  1., ...,  2.,  5.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[20., 27., 23., ...,  3.,  0.,  0.],\n",
       "        [ 8., 14., 21., ...,  2.,  2.,  0.],\n",
       "        [10., 23., 25., ...,  2.,  2.,  0.],\n",
       "        ...,\n",
       "        [ 2.,  5.,  5., ...,  7.,  2.,  0.],\n",
       "        [ 1.,  5.,  1., ...,  7.,  5.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[27., 10., 35., ...,  1.,  5.,  0.],\n",
       "        [12.,  6., 23., ...,  1.,  3.,  0.],\n",
       "        [25., 12.,  4., ...,  2.,  3.,  0.],\n",
       "        ...,\n",
       "        [ 9.,  9.,  1., ...,  2.,  2.,  0.],\n",
       "        [ 6.,  4.,  7., ...,  1.,  1.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 8., 23., 25., ...,  2.,  5.,  0.],\n",
       "        [42., 51.,  6., ...,  0.,  6.,  0.],\n",
       "        [21., 31., 40., ...,  3.,  1.,  0.],\n",
       "        ...,\n",
       "        [ 6.,  7.,  4., ...,  5.,  2.,  0.],\n",
       "        [ 4.,  2.,  6., ...,  5.,  1.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_data = t1_img.get_data()\n",
    "t1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t1_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element in the array corresponds to an intensity value. The range of values typically goes from 0 (black) to 255 (white)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check some basic properties of the array.  \n",
    "The `type()` function will only tell you that a variable is a NumPy array. It won’t tell you the type of data inside of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<f4')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the NumPy array’s elements are floating-point numbers.   \n",
    "The data type of an image controls the range of possible intensities. As the number of possible values increases, the amount of space the image takes up in memory also increases.\n",
    "\n",
    "| Data Type | Range | Number of Values |\n",
    "|---|---|---|\n",
    "| uint8 | 0, 255 | 256 |\n",
    "| uint16 | -128, 127 | 256 |\n",
    "| uint 16 | 0, 2^16 | 2^16 |\n",
    "| int16 | -2^15, 2^15 | 2^16 |\n",
    "| float16 | ~-2^16, ~2^16 | >>2^16 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=exercise>\n",
    "    <b>EXERCISE:</b> How can we see the number of dimensions in the <code>t1_data</code> array? What about the array's shape? Once again, all of the attributes of the array can be seen by typing <code>t1_data.</code> and <kbd>Tab</kbd>.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=solution>\n",
    "    <b>SOLUTION:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 256, 256)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the data always has at least 3 dimensions (X, Y, and Z) and sometimes a 4th, T (time).  \n",
    "This T1w image has 3 dimensions. This means that the brain was scanned in 176 slices with a resolution of 256 x 256 voxels per slice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/profile/Humera_Tariq/publication/280608869/figure/fig8/AS:668641804681226@1536428037484/Voxel-and-slice-in-3D-MRI-data.jpg\"/>\n",
    "\n",
    "Tariq, Humera & Burney, S.M.Aqil. (2014). Brain MRI literature review for interdisciplinary studies. Journal of biomedical graphics and computing. 4. 41-53. 10.5430/jbgc.v4n4p41. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. [Affine](http://nipy.org/nibabel/coordinate_systems.html): tells the position of the image array data in a *reference space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The affine array tells the position of the image array data in a *reference space*. It translates between data-space and world-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_affine = t1_img.affine\n",
    "t1_affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=exercise>\n",
    "    <b>EXERCISE:</b> Explore some of the other methods that can be called on the NIfTI image.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With Image Data\n",
    "\n",
    "#### Slicing\n",
    "\n",
    "n-dimensional images are just stacks of numpy arrays.  Each value in the array is assigned to an x, y or z coordinate.  \n",
    "<img src=\"../static/images/numpy_arrays.png\" alt=\"Drawing\" align=\"middle\" width=\"500px\"/>\n",
    "\n",
    "You'll recall our example T1w image is a 3D image with dimensions $176 \\times 256 \\times 256$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing does exactly what it seems to imply. Giving our 3D volume, we pull out a 2D slice of our data. Here's an example of slicing from left to right (**sagittal slicing**):\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/56/Parasagittal_MRI_of_human_head_in_patient_with_benign_familial_macrocephaly_prior_to_brain_injury_%28ANIMATED%29.gif\"/>\n",
    "\n",
    "This gif is a series of 2D images or **slices** moving from left to right. We'll now look into how we can pull slices from our 3D image\n",
    "\n",
    "***\n",
    "Sourced from: https://en.wikipedia.org/wiki/Neuroimaging#/media/File:Parasagittal_MRI_of_human_head_in_patient_with_benign_familial_macrocephaly_prior_to_brain_injury_(ANIMATED).gif\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have two ways of working with neuroimaging data. \n",
    "\n",
    "\n",
    "1. We have the actual <code>t1_img</code> we loaded using <code>nibabel</code>\n",
    "2. We have the array we pulled from <code>t1_img</code> in the form of <code>t1_data</code>\n",
    "\n",
    "\n",
    "For each of these representations of our data we can pull \"slices\" using different methods.\n",
    "\n",
    "\n",
    "First we'll work with the array in the form of <code>t1_img</code>. Since this is a <code>numpy</code> array, we can use the same method as we'd use when dealing with 3D arrays in python (R and MATLAB are very similar here!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull the 10th \"sagittal slice\"\n",
    "sagittal_slice = t1_data[10,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the following structure: \n",
    "\n",
    "1. We can **index** an array using the array followed by square brackets as follows t1_data[x,y,z]\n",
    "\n",
    "With our data:\n",
    "- <code>x</code> is the left to right index\n",
    "- <code>y</code> is the back to front index\n",
    "- <code>z</code> is the bottom to top index\n",
    "\n",
    "\n",
    "So here we're selecting the 10th slice going from left to right (there are 176 slices going from left to right!)\n",
    "\n",
    "The <code>:</code>, indicates that we want to grab *everything*. \n",
    "\n",
    "In plain english we want to:\n",
    "\n",
    "**Move 10 spots from the left, then grab a full 2D picture here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Now try selecting the 70th slice from the back (this is called a **coronal slice**).\n",
    "It helps to think of this as follows:\n",
    "\n",
    "**Move 70 spots from the back, then grab the full 2D picture here**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coronal_slice = t1_data[:,70,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally try grabbing a **axial slice**, specifically the 126th slice from the bottom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_slice = t1_data[:,:,126]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier we can also slice using <code>t1_img</code>, which we loaded through <code>nibabel</code>. It's sometimes nicer to work with this since we don't have to deal with arrays directly like we did with <code>t1_data</code>. \n",
    "\n",
    "Slicing with <code>t1_img</code> is just as straightforward and involves using <code>t1_img.slicer[x,y,z]</code>, but with a single caveat which we'll demonstrate here using the 10th slice from the left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagittal_slice = t1_img.slicer[10:11,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference? Here we have to format a sagittal slice as follows:\n",
    "\n",
    "<code>t1_img.slicer[ (slice) :  (slice# +1) ,:,:]</code>\n",
    "\n",
    "This is just a result of how <code>slicer</code> is programmed, but everything else remains the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Use <code>t1_img.slicer</code> to select the:\n",
    "\n",
    "1. 70th coronal slice from the back\n",
    "2. 126th axial slice from the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coronal slice\n",
    "coronal_slice = t1_img.slicer[:,70:71,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Axial Slice\n",
    "axial_slice = t1_img.slicer[:,:,126:127]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been slicing and dicing brain images but we have no idea what they look like! In the next section we'll show you how you can visualize brain slices using <code>nibabel</code>!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing\n",
    "If we wanted to get a quick view of our data, Nibabel provides this functionality through a method called <code>orthoview()</code>. Here's how it looks in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_img.orthoview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we wanted to view *the central slice?*. With <code>orthoview()</code>, we can only get a quick peek at the data. Nibabel also provides a tool called <code>nib.viewers.OrthoSlicer3D</code> which can help us be a bit more picky about how we want to view our images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicer_viewer = nib.viewers.OrthoSlicer3D(t1_img.get_data())\n",
    "slicer_viewer.set_position(x=86,y=150,z=160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy has a `reshape()` function for reshaping the data array. Let's say we want to convert this 3D array into a a 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data_2d = t1_data.reshape(np.prod(t1_data.shape[:-1]), t1_data.shape[-1])\n",
    "t1_data_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masks\n",
    "Next, we will see how to segment the brain from the black background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(t1_data.flatten(), bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_mask = t1_data > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(t1_mask[87, :, :], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.where(t1_mask, t1_data, 0)\n",
    "plt.imshow(test[87, :, :], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing NIfTI Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the mask we just created to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask = nib.Nifti1Image(test, t1_affine, t1_hdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask.to_filename('../data/test_mask.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri_venv",
   "language": "python",
   "name": "fmri_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
