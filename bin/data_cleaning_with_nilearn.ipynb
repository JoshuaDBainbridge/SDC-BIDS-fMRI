{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction to functional data cleaning using nilearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movement is the enemy of neuroimagers\n",
    "\n",
    "In task-based fMRI, if participants move during task-relevant moments\n",
    "- Get a huge **false task-related signal** thatâ€™s actually due to motion!\n",
    "\n",
    "In resting-state fMRI, movement can induce **false correlations** between brain regions\n",
    "\n",
    "\n",
    "Solving for this involves *modelling* our fMRI signal to be comprised of **true brain signal** and **confounder signals**. \n",
    "\n",
    "\n",
    "Our goal is to remove a majority (hopefully) of the **confounder signals** and acquire something *closer* to the **true signal**. \n",
    "\n",
    "This is achieved via **confound regression**, which is essentially fitting a linear model using confounds as regressors then subtracting it out from the signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nilearn import image as img\n",
    "from nilearn import plotting as plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Implementing Confound Regression using FMRIPREP outputs\n",
    "FMRIPREP estimates confounds for the functional image and outputs it into:\n",
    "\n",
    "**sub-xxxxx_task-xxxx_space-xxxx_..._confounds.tsv**\n",
    "\n",
    "Let's load one up and see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_dir = '../data/func/'\n",
    "os.listdir(func_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confounds file is organized like an excel spread-sheet with multiple columns, each for a specific confound.\n",
    "\n",
    "We can view these using pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = os.path.join(func_dir,\n",
    "                    'sub-10557_task-rest_bold_space-MNI152NLin2009cAsym_preproc.nii.gz')\n",
    "confound = os.path.join(func_dir,\n",
    "                        'sub-10557_task-rest_bold_confounds.tsv'\n",
    "                        )\n",
    "confound_df = pd.read_csv(confound,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confound_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these confounds is computed automatically by fmriprep. The choice of which confounds to use in functional imaging analysis is a source of large debate. We recommend that you check out these sources for a start:\n",
    "\n",
    "1. https://www.sciencedirect.com/science/article/pii/S1053811917302288#f0005\n",
    "2. https://www.sciencedirect.com/science/article/pii/S1053811917302288\n",
    "\n",
    "For now we're going to replicate the pre-processing (mostly) from the seminal Yeo1000 17-networks paper:\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pubmed/21653723"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The (mostly, slightly modified) Yeo 2011 Pre-processing schema\n",
    "\n",
    "#### Confound regressors\n",
    "1. 6 motion parameters (X, Y, Z, RotX, RotY, RotZ) \n",
    "2. Global signal (GlobalSignal)\n",
    "3. 2 Largest Principal components of non-grey matter (aCompCor01, aCompCor02)   \n",
    "\n",
    "This is a total of 9 base confound regressor variables. Finally we add temporal derivatives of each of these signals as well (1 temporal derivative for each), the result is 18 confound regressors.\n",
    "\n",
    "#### Low/High pass filtering\n",
    "1. Low pass filtering cutoff: 0.08 \n",
    "2. High pass filtering cutoff: 0.009\n",
    "\n",
    "Low pass filters out high frequency signals from our data. fMRI signals are slow evolving processes, any high frequency signals are likely due to noise \n",
    "High pass filters out any very low frequency signals (below 0.009Hz), which may be due to intrinsic scanner instabilities\n",
    "\n",
    "#### Drop dummy TRs\n",
    "During the initial stages of a functional scan there is a strong signal decay artifact, thus the first 4ish or so \n",
    "TRs are very high intensity signals that don't reflect the rest of the scan. Therefore we drop these timepoints. \n",
    "\n",
    "#### Censoring + Interpolation (leaving out)\n",
    "Censoring involves removal and interpolation of high-movement frames from the fMRI data. Interpolation is typically done using sophisticated algorithms much like [Power et al. 2014](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3849338/). \n",
    "\n",
    "** We won't be using censoring + interpolation since its fairly complicated and would take up too much time **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Confound variables for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing temporal derivatives for confound variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confound_vars = ['X','Y','Z','RotX','RotY','RotZ','GlobalSignal','aCompCor01','aCompCor02']\n",
    "confound_df = confound_df[confound_vars]\n",
    "confound_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each of these columns we want to compute the temporal derivative, we'll use a for-loop for simplicity\n",
    "for col in confound_df.columns:\n",
    "    \n",
    "    #Example X --> X_dt\n",
    "    new_name = '{}_dt'.format(col) \n",
    "    \n",
    "    #Compute differences for each pair of rows from start to end. \n",
    "    new_col = confound_df[col].diff() \n",
    "    \n",
    "    #Make new column in our dataframe\n",
    "    confound_df[new_name] = new_col\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confound_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have noticed, we have NaN's in our {confound}_dt. This happens because there is no prior value to the first index to take a difference with, but this isn't a problem since we're going to be dropping 4 timepoints from our data and confounders anyway!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy TR Drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we'll load in our data and check the shape\n",
    "raw_func_img = img.load_img(func)\n",
    "raw_func_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the fourth dimension represents frames/TRs(timepoints). We want to drop the first four timepoints entirely, to do so we use nibabel's slicer feature. We'll also drop the first 4 confound variable timepoints to match the functional scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_img = raw_func_img.slicer[:,:,:,5:]\n",
    "func_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop confound dummy TRs\n",
    "drop_confound_df = confound_df.loc[5:]\n",
    "print(drop_confound_df.shape) #number of rows should match that of the functional image\n",
    "drop_confound_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying confound regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'd like to clean our data of our selected confound variables. This is easily done using nilearn's signal.clean function which looks like:\n",
    "\n",
    "sgl.clean(signals, confounds, low_pass, high_pass)\n",
    "\n",
    "Where:\n",
    "- **signals** represents a matrix of time-series (one column per voxel time-series)\n",
    "- **confounds** a matrix representing our confound variables (one column per confound)\n",
    "- **low_pass** the low-pass cutoff\n",
    "- **high_pass** the high-pass cutoff\n",
    "\n",
    "This means we need to convert our data and confounds into a matrix format that signal.clean can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nilearn import signal as sgl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Set up our data signals matrix\n",
    "Recall our data is a 4D array, with the fourth dimension represented as time and the other 3 dimensions representing the (x,y,z) coordinate of a particular voxel. We want to convert this to a matrix represented as the following:\n",
    "\n",
    "$$\n",
    "\\left.\\left( \n",
    "\\vphantom{ \\begin{array}{c} 1 \\\\ 1 \\\\1 \\\\1 \\\\1 \\end{array} }\n",
    "\\smash{ \\underbrace{\n",
    "                    \\begin{array}{cccccc} \n",
    "                    x & x & x & \\cdots & x & \\\\\n",
    "                    x & x & x & \\cdots & x &\\\\\n",
    "                    x & x & x & \\cdots & x &\\\\\n",
    "                    x & x & x & \\cdots & x &\\\\\n",
    "                    x & x & x & \\cdots & x & \n",
    "                    \\end{array}\n",
    "                   }_{x*y*z \\text{ voxels }}\n",
    "      }\n",
    "\\right)\n",
    "\\right\\}\\,t\\text{ number of frames}\n",
    "$$\n",
    "\n",
    "<br><br>\n",
    "- The **number of columns represents the total number of voxels (x\\*y\\*z)**, each column being a single voxel\n",
    "- The **number of rows represents the number of timepoints**\n",
    "\n",
    "So we need to *reshape* our data to match this! This is done easily with a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we pull out our data as a numpy arrays\n",
    "signal = func_img.get_data()\n",
    "\n",
    "#Then we get x,y,z dimensions\n",
    "x,y,z,t = signal.shape[0],signal.shape[1],signal.shape[2], signal.shape[3]\n",
    "\n",
    "#Then we get total number of voxels, x*y*z\n",
    "total_voxels = x*y*z\n",
    "\n",
    "#Then we reshape to the correct size, note that matrix is flipped on its side\n",
    "#Where the number of rows matches the number of voxels instead of time-series\n",
    "shaped_signal = signal.reshape([total_voxels,t])\n",
    "print(shaped_signal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we flip it over (switch columns and rows) \n",
    "shaped_signal = shaped_signal.transpose() \n",
    "print(shaped_signal.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Set up our confound matrix\n",
    "Recall that we need our confounds matrix to be a matrix with: \n",
    "- A row for each timepoint\n",
    "- A column for each confound variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert our table to a matrix\n",
    "confound_mat = drop_confound_df.as_matrix()\n",
    "print(confound_mat.shape) #it is easily converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Cleaning our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up variables for confound regression\n",
    "low_pass = 0.08 \n",
    "high_pass = 0.009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply!\n",
    "cleaned_signal = sgl.clean(shaped_signal,confounds=confound_mat,low_pass=low_pass,high_pass=high_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can reconstruct our signal, just perform operations in reverse\n",
    "#Step 1: Flip it back\n",
    "cleaned_signal = cleaned_signal.transpose() \n",
    "\n",
    "#Step 2: Reshape it back into a 4D time-series\n",
    "cleaned_brain = cleaned_signal.reshape([x,y,z,t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_img = nib.Nifti1Image(cleaned_brain,np.eye(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done!\n",
    "Hopefully you've learned a bit about how FMRIPREP stores confound regressors and how we can work with it to clean our functional data. \n",
    "In the final functional connectivity analysis, we will use the same techniques (except conveniently wrapped versions) to clean all our data and compute seed-based functional connectivity maps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
